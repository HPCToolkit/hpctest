SLURM NOTES

Doumentation at https://slurm.schedmd.com

--------------------------------------------------------------------------
The application appears to have been direct launched using "srun",
but OMPI was not built with SLURM support. This usually happens
when OMPI was not configured --with-slurm and we weren't able
to discover a SLURM installation in the usual places.

Please configure as appropriate and try again.
--------------------------------------------------------------------------



...............................................................................
--PTY option
...............................................................................
12. How can I get shell prompts in interactive mode?
srun --pty bash -i
Srun's --pty option runs task zero in pseudo terminal mode. Bash's -i option tells it to run in interactive mode (with prompts). 
You can also configure SallocDefaultCommand in slurm.conf to automatically launch a shell, e.g.:

SallocDefaultCommand="srun -n1 -N1 --mem-per-cpu=0 --pty --preserve-env --cpu-bind=no --mpi=none $SHELL"
And then run salloc directly which will provide you an allocation with an interactive shell console.


13. How can I get the task ID in the output or error file name for a batch job?

If you want separate output by task, you will need to build a script containing this specification. For example:

$ cat test
#!/bin/sh
echo begin_test
srun -o out_%j_%t hostname

$ sbatch -n7 -o out_%j test
sbatch: Submitted batch job 65541

$ ls -l out*
-rw-rw-r--  1 jette jette 11 Jun 15 09:15 out_65541
-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_0
-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_1
-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_2
-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_3
-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_4
-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_5
-rw-rw-r--  1 jette jette  6 Jun 15 09:15 out_65541_6
...............................................................................


...............................................................................
#!/bin/bash
#SBATCH --job-name=YourJobNameHere
#SBATCH --account=commons
#SBATCH --partition=commons
#SBATCH --export=ALL
#SBATCH --nodes=1
#SBATCH --exclusive				# optional
#SBATCH --ntasks=1
#SBATCH --ntasks-per-node=2
#SBATCH --cpus-per-task=4
#SBATCH --mem-per-cpu=1000m
#SBATCH --time=00:30:00
#SBATCH --output=mypath
#SBATCH --error=mypath
#SBATCH --mail-user=YourEmailAddressHere
#SBATCH --mail-type=ALL
Â 
<shell code for the job>
...............................................................................
#!/bin/bash
#SBATCH --job-name=AMG2013
#SBATCH --account=commons
#SBATCH --partition=commons
#### #SBATCH --partition=interactive
#### #SBATCH --export=ALL
#### #SBATCH --nodes=2
#### #SBATCH --exclusive				# optional
#SBATCH --ntasks=8
#### #SBATCH --ntasks-per-node=4
#SBATCH --cpus-per-task=2
#SBATCH --mem-per-cpu=1000m
#SBATCH --time=00:30:00
#### #SBATCH --output=mypath
#### #SBATCH --error=mypath
#SBATCH --mail-user=scott@rice.edu
#SBATCH --mail-type=ALL
hpctest run app/AMG2013 --verbose --debug
...............................................................................


sbatch  /path/to/myjob.slurm
squeue  -j jobID -o "%T"
scancel jobID

Running statuses:
COMPLETED 

Terminated statuses:
BOOT_FAIL CANCELLED DEADLINE FAILED NODE_FAIL OUT_OF_MEMORY PREEMPTED REVOKED TIMEOUT



BOOT_FAIL
Job terminated due to launch failure, typically due to a hardware failure (e.g. unable to boot the node or block
and the job can not be requeued).

CANCELLED
Job was explicitly cancelled by the user or system administrator. The job may or may not have been initiated.

COMPLETED
Job has terminated all processes on all nodes with an exit code of zero.

CONFIGURING
Job has been allocated resources, but are waiting for them to become ready for use (e.g. booting).

COMPLETING
Job is in the process of completing. Some processes on some nodes may still be active.

DEADLINE
Job terminated on deadline.

FAILED
Job terminated with non-zero exit code or other failure condition.

NODE_FAIL
Job terminated due to failure of one or more allocated nodes.

OUT_OF_MEMORY
Job experienced out of memory error.

PENDING
Job is awaiting resource allocation.

PREEMPTED
Job terminated due to preemption.

RUNNING
Job currently has an allocation.

RESV_DEL_HOLD
Job is held.

REQUEUE_FED
Job is being requeued by a federation.

REQUEUE_HOLD
Held job is being requeued.

REQUEUED
Completing job is being requeued.

RESIZING
Job is about to change size.

REVOKED
Sibling was removed from cluster due to other cluster starting the job.

SIGNALING
Job is being signaled.

SPECIAL_EXIT
The job was requeued in a special state. This state can be set by users, typically in EpilogSlurmctld,
if the job has terminated with a particular exit value.

STAGE_OUT
Job is staging out files.

STOPPED
Job has an allocation, but execution has been stopped with SIGSTOP signal. CPUS have been retained by this job.

SUSPENDED
Job has an allocation, but execution has been suspended and CPUs have been released for other jobs.

TIMEOUT
Job terminated upon reaching its time limit.


The use of --ntasks will place tasks on available nodes for throughput purposes.
- If you request --ntasks=16 and there are 3 nodes with 8 CPUs and a total of 16 available free CPUs
  then your job will be allocated to those free CPUs.
- Additionally, if there are any minimum node requirements then --ntasks will understand and accommodate
  such a requirement. Meaning it will allocate the minimum number of nodes necessary to satisfy the scheduler.

The use of --ntasks-per-node will place the same number of tasks on each node requested.
- Additionally, if there are any minimum node requirements then --ntasks-per-node will understand and accommodate
  such a requirement. Meaning it will allocate the minimum number of nodes necessary to satisfy the scheduler.
- The use of --nodes by itself has a default of --ntasks-per-node=1.

If your --mem value multiplied by the number of tasks (--ntasks-per-node)
exceeds the amount of memory per node, your job will not run.




